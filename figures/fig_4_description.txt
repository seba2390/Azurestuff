N = 4, k = 2, max_iterations = 1000, alpha=0.5, Averaged over 100 runs.

Using grid w. following initialization strategy:
                [[0,1],
	             [1,0]]

Used Nearest-Neighbor interactions only.
Initial parameters sampled random uniformly in [-2*pi;2*pi]
Used COBYLA to optimize.

The normalization of the cost on the right figure is done wrt. the max cost
of a 'N' choose 'K' state (the subspace), and since it is possible to sample
constraint violating states from QAOA the cost might be bigger than 1.
As such one might interpert the y-axis as "the number of times the
cost is bigger than the max cost of the subspace".

1 Layer:
CP-VQA          : 4 angles (parameters)
CP-VQA + Z-PHASE: 8 angles (parameters)
QAOA            : 2 angles (parameters)

2 Layers:
CP-VQA          : 8 angles (parameters)
CP-VQA + Z-PHASE: 16 angles (parameters)
QAOA            : 4 angles (parameters)

3 Layers:
CP-VQA          : 12 angles (parameters)
CP-VQA + Z-PHASE: 24 angles (parameters)
QAOA            : 6 angles (parameters)

4 Layers:
CP-VQA          : 16 angles (parameters)
CP-VQA + Z-PHASE: 32 angles (parameters)
QAOA            : 8 angles (parameters)

5 Layers:
CP-VQA          : 20 angles (parameters)
CP-VQA + Z-PHASE: 40 angles (parameters)
QAOA            : 10 angles (parameters)

maybe the big difference in #parameters are a part of the explenation in the difference in the results,
i.e. - to few parameters makes ansatz "under-parametrized" and vice-verca ?
