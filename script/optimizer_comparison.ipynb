{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-19T22:42:58.190210Z",
     "start_time": "2024-02-19T22:42:58.179956Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from src.CP_VQA.Qulacs_CP_VQA import Qulacs_CP_VQA\n",
    "\n",
    "from src.Qubo import Qubo\n",
    "from src.Chain import Chain\n",
    "from src.Tools import (portfolio_metrics, \n",
    "                       min_cost_partition, \n",
    "                       get_qubo, \n",
    "                       qubo_limits, \n",
    "                       check_qubo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def simulate(settings: dict):\n",
    "    result = {'N':settings['N']}\n",
    "    # Generating random problem instance \n",
    "    expected_returns, covariances = portfolio_metrics(n=settings['N'], seed=settings['seed'])\n",
    "    # Retrieving C_min, C_max and corresponding states for original portfolio problem\n",
    "    constrained_result, full_result, lmbda = min_cost_partition(nr_qubits=settings['N'],\n",
    "                                                                k=settings['k'],\n",
    "                                                                mu=expected_returns,\n",
    "                                                                sigma=covariances,\n",
    "                                                                alpha=settings['alpha'])\n",
    "\n",
    "    # Generating QUBO corresponding to current problem instance\n",
    "    Q, offset = get_qubo(mu=expected_returns,\n",
    "                         sigma=covariances, \n",
    "                         alpha=settings['alpha'],\n",
    "                         lmbda=lmbda+1, # Adding small constant purposely\n",
    "                         k=settings['k'])\n",
    "    qubo = Qubo(Q=Q, offset=offset) \n",
    "    qubo.subspace_c_min, qubo.subspace_c_max = constrained_result['c_min'], constrained_result['c_max']\n",
    "    qubo.subspace_x_min, qubo.subspace_x_max = constrained_result['s_min'], constrained_result['s_max']\n",
    "    qubo.full_space_c_min, qubo.full_space_c_max = full_result['c_min'], full_result['c_max']\n",
    "    check_qubo(QUBO_matrix=Q, QUBO_offset=offset, expected_returns=expected_returns, covariances=covariances, alpha=settings['alpha'], k=settings['k'])\n",
    "     \n",
    "\n",
    "    \n",
    "    bfgs = Qulacs_CP_VQA(N_qubits=settings['N'],\n",
    "                       cardinality=settings['k'],\n",
    "                       layers=settings['L'],\n",
    "                       topology=settings['topology'],\n",
    "                       with_next_nearest_neighbors=settings['w_nnn'],\n",
    "                       get_full_state_vector=False,\n",
    "                       qubo=qubo)\n",
    "     \n",
    "    cobyla = Qulacs_CP_VQA(N_qubits=settings['N'],\n",
    "                           cardinality=settings['k'],\n",
    "                           layers=settings['L'],\n",
    "                           topology=settings['topology'],\n",
    "                           with_next_nearest_neighbors=settings['w_nnn'],\n",
    "                           get_full_state_vector=False,\n",
    "                           qubo=qubo)\n",
    "\n",
    "    \n",
    "     # Generating initial guess for rotation angles\n",
    "    np.random.seed(settings['seed'])\n",
    "    theta_min, theta_max = -2*np.pi, 2*np.pi\n",
    "    N_angles = settings['L'] * len(settings['topology'].get_NNN_indices()) if settings['w_nnn'] else settings['L'] * len(settings['topology'].get_NN_indices())\n",
    "    CPVQA_theta_i = np.random.uniform(theta_min, theta_max, N_angles)\n",
    "    \n",
    "    bfgs_sim_res = sc.optimize.minimize(fun=bfgs.get_cost, \n",
    "                                        x0=CPVQA_theta_i,\n",
    "                                        method='BFGS',\n",
    "                                        options={'disp': False, \n",
    "                                                 'maxiter': settings['max_iter']},\n",
    "                                        callback=bfgs.callback)\n",
    "    bfgs_norm_c = np.min(bfgs.normalized_costs)\n",
    "    bfgs_p = np.max(bfgs.opt_state_probabilities)    \n",
    "    \n",
    "    \n",
    "    cobyla_sim_res = sc.optimize.minimize(fun=cobyla.get_cost, \n",
    "                                          x0=CPVQA_theta_i,\n",
    "                                          method='COBYLA',\n",
    "                                          options={'disp': False, \n",
    "                                                   'maxiter': settings['max_iter']},\n",
    "                                          callback=cobyla.callback)\n",
    "    cobyla_norm_c = np.min(cobyla.normalized_costs)\n",
    "    cobyla_p = np.max(cobyla.opt_state_probabilities)\n",
    "    \n",
    "    return  {'N':settings['N'], \n",
    "             'bfgs': {'c':bfgs_norm_c,'p':bfgs_p}, \n",
    "             'cobyla': {'c':cobyla_norm_c,'p':cobyla_p}}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T22:44:38.758964Z",
     "start_time": "2024-02-19T22:44:38.746861Z"
    }
   },
   "id": "d4c30a1c5082473c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "layer_dict = {2:1,  3:1,  4:1,\n",
    "              5:2,  6:2,  7:3,\n",
    "              8:5,  9:6,  10:6,\n",
    "              11:5, 12:5, 13:5,\n",
    "              14:5, 15:5, 16:5,\n",
    "              17:6, 18:6, 19:6, \n",
    "              20:7, 21:7, 22:7}\n",
    "\n",
    "max_iter = 1000\n",
    "alpha=0.5\n",
    "N_seeds = 5\n",
    "N_min, N_max = 2, 10\n",
    "sim_settings = []\n",
    "for seed in range(N_seeds):\n",
    "    for N in range(N_min, N_max+1):\n",
    "        topology = Chain(N_qubits=N)\n",
    "        topology.set_initialization_strategy(strategy=np.array([0 if i%2 == 0 else 1 for i in range(N)]))\n",
    "        setting = {'N'         :N,       'alpha'   :alpha,   'L'       :layer_dict[N], \n",
    "                   'seed'      :seed,    'topology':topology,'max_iter':max_iter,\n",
    "                   'opt_method':'COBYLA','w_nnn'   :True,    'k'       :N//2}\n",
    "        sim_settings.append(setting)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T22:44:39.278031Z",
     "start_time": "2024-02-19T22:44:39.275602Z"
    }
   },
   "id": "9bc81a570645737a"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31m_RemoteTraceback\u001B[0m                          Traceback (most recent call last)",
      "\u001B[0;31m_RemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/sebastianyde/miniforge3/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/Users/sebastianyde/miniforge3/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/sebastianyde/miniforge3/lib/python3.10/site-packages/joblib/parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n  File \"/Users/sebastianyde/miniforge3/lib/python3.10/site-packages/joblib/parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/var/folders/lf/g00xwz855rs9xhsrn28h139c0000gn/T/ipykernel_9554/3234741907.py\", line 55, in simulate\n  File \"/Users/sebastianyde/miniforge3/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 2953, in min\n    return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n  File \"/Users/sebastianyde/miniforge3/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 88, in _wrapreduction\n    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\nValueError: zero-size array to reduction operation minimum which has no identity\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [13], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m N_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m15\u001B[39m\n\u001B[0;32m----> 2\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mN_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m51\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mloky\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43msimulate\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43msetting\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msetting\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msim_settings\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/parallel.py:1952\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1946\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[1;32m   1947\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[1;32m   1948\u001B[0m \u001B[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001B[39;00m\n\u001B[1;32m   1949\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[1;32m   1950\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 1952\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/parallel.py:1595\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[0;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[1;32m   1592\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[1;32m   1594\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1595\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[1;32m   1597\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[1;32m   1598\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[1;32m   1599\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[1;32m   1600\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[1;32m   1601\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/parallel.py:1699\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1692\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_retrieval():\n\u001B[1;32m   1693\u001B[0m \n\u001B[1;32m   1694\u001B[0m     \u001B[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001B[39;00m\n\u001B[1;32m   1695\u001B[0m     \u001B[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001B[39;00m\n\u001B[1;32m   1696\u001B[0m     \u001B[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001B[39;00m\n\u001B[1;32m   1697\u001B[0m     \u001B[38;5;66;03m# worker traceback.\u001B[39;00m\n\u001B[1;32m   1698\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aborting:\n\u001B[0;32m-> 1699\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_error_fast\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1700\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m   1702\u001B[0m     \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[1;32m   1703\u001B[0m     \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/parallel.py:1734\u001B[0m, in \u001B[0;36mParallel._raise_error_fast\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1730\u001B[0m \u001B[38;5;66;03m# If this error job exists, immediatly raise the error by\u001B[39;00m\n\u001B[1;32m   1731\u001B[0m \u001B[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001B[39;00m\n\u001B[1;32m   1732\u001B[0m \u001B[38;5;66;03m# called directly or if the generator is gc'ed.\u001B[39;00m\n\u001B[1;32m   1733\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m error_job \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1734\u001B[0m     \u001B[43merror_job\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_result\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/parallel.py:736\u001B[0m, in \u001B[0;36mBatchCompletionCallBack.get_result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    730\u001B[0m backend \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparallel\u001B[38;5;241m.\u001B[39m_backend\n\u001B[1;32m    732\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend\u001B[38;5;241m.\u001B[39msupports_retrieve_callback:\n\u001B[1;32m    733\u001B[0m     \u001B[38;5;66;03m# We assume that the result has already been retrieved by the\u001B[39;00m\n\u001B[1;32m    734\u001B[0m     \u001B[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001B[39;00m\n\u001B[1;32m    735\u001B[0m     \u001B[38;5;66;03m# be returned.\u001B[39;00m\n\u001B[0;32m--> 736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_return_or_raise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    738\u001B[0m \u001B[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001B[39;00m\n\u001B[1;32m    739\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/parallel.py:754\u001B[0m, in \u001B[0;36mBatchCompletionCallBack._return_or_raise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    752\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    753\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m TASK_ERROR:\n\u001B[0;32m--> 754\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n\u001B[1;32m    755\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n\u001B[1;32m    756\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "N_jobs=15\n",
    "r = Parallel(n_jobs=N_jobs, verbose=51, backend='loky')(delayed(simulate)(setting) for setting in sim_settings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T22:44:40.045981Z",
     "start_time": "2024-02-19T22:44:39.838620Z"
    }
   },
   "id": "147cf0f0972c237"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "qiskit_res  = {N: [] for N in range(N_min,N_max+1)}\n",
    "qulacs_res  = {N: [] for N in range(N_min,N_max+1)}\n",
    "qsim_res    = {N: [] for N in range(N_min,N_max+1)}\n",
    "spynoza_res = {N: [] for N in range(N_min,N_max+1)}\n",
    "\n",
    "for res in r: \n",
    "    if res['qiskit'] is not None:\n",
    "        qiskit_res[res['N']].append(res['qiskit'])\n",
    "    if res['qulacs'] is not None:\n",
    "        qulacs_res[res['N']].append(res['qulacs'])\n",
    "    \"\"\"if res['qsim'] is not None:\n",
    "        qsim_res[res['N']].append(res['qsim'])\"\"\"\n",
    "    if res['spynoza'] is not None:\n",
    "        spynoza_res[res['N']].append(res['spynoza'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e36b437b5db86011"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qiskit_avgs = np.array([[np.mean(qiskit_res[key]), np.std(qiskit_res[key])] for key in qiskit_res.keys()])\n",
    "qsim_avgs = np.array([[np.mean(qsim_res[key]), np.std(qsim_res[key])] for key in qsim_res.keys()])\n",
    "qulacs_avgs = np.array([[np.mean(qulacs_res[key]), np.std(qulacs_res[key])] for key in qulacs_res.keys()])\n",
    "spynoza_avgs = np.array([[np.mean(spynoza_res[key]), np.std(spynoza_res[key])] for key in spynoza_res.keys()])\n",
    "\n",
    "N_vals = [n for n in range(N_min, N_max+1)]\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,4))\n",
    "\n",
    "ax.set_title('CP-VQA Statevector (CPU),  (6N-4 Cnot-gates pr. layer)')\n",
    "\n",
    "ax.errorbar(N_vals, qiskit_avgs[:,0], yerr=qiskit_avgs[:,1], fmt='.-', capsize=2, label='Qiskit', color='tab:blue')\n",
    "#ax.errorbar(N_vals, qsim_avgs[:,0], yerr=qsim_avgs[:,1], fmt='.-', capsize=2, label='Qsim', color='tab:red')\n",
    "ax.errorbar(N_vals, spynoza_avgs[:,0], yerr=spynoza_avgs[:,1], fmt='.-', capsize=2, label='Spynoza', color='tab:red')\n",
    "\n",
    "ax.errorbar(N_vals, qulacs_avgs[:,0], yerr=qulacs_avgs[:,1], fmt='.-', capsize=2, label='Qulacs', color='tab:green')\n",
    "ax.hlines(0, N_vals[0], N_vals[-1],ls='--',color='k', lw = 1)\n",
    "ax.set_ylabel('time per iteration [s]')\n",
    "ax.set_xlabel('# Qubits')\n",
    "ax.set_xticks(N_vals)\n",
    "\n",
    "ax.fill_between(np.linspace(4,6,100), -np.ones(100)*0.1, np.ones(100)*0.3, alpha=0.2, color='k')\n",
    "ax.text(4.3,0.225,'1 layer')\n",
    "\n",
    "ax.fill_between(np.linspace(7,9,100), -np.ones(100)*0.1, np.ones(100)*0.3, alpha=0.2, color='k')\n",
    "ax.text(7.3,0.225,'2 layers')\n",
    "\n",
    "ax.fill_between(np.linspace(10,12,100), -np.ones(100)*0.1, np.ones(100)*0.3, alpha=0.2, color='k')\n",
    "ax.text(10.3,0.225,'3 layers')\n",
    "\n",
    "ax.fill_between(np.linspace(13,15,100), -np.ones(100)*0.1, np.ones(100)*0.3, alpha=0.2, color='k')\n",
    "ax.text(13.3,0.225,'4 layers')\n",
    "\n",
    "ax.fill_between(np.linspace(16,18,100), -np.ones(100)*0.1, np.ones(100)*0.3, alpha=0.2, color='k')\n",
    "ax.text(16.3,0.075,'5 layers')\n",
    "\n",
    "\"\"\"ax.fill_between(np.linspace(19,21,100), -np.ones(100)*0.1, np.ones(100)*2.5, alpha=0.2, color='k')\n",
    "ax.text(19.5,2,'6 layers')\"\"\"\n",
    "\n",
    "################## miniplot ##################\n",
    "# inset axes....\n",
    "axins_x_left, axins_y_lower, axins_x_width, axins_height = 0.08, 0.42, 0.575, 0.3\n",
    "axins = ax.inset_axes([axins_x_left, axins_y_lower, axins_x_width, axins_height])\n",
    "axins.errorbar(N_vals, qiskit_avgs[:,0], yerr=qiskit_avgs[:,1], fmt='.-', capsize=2, label='Qiskit', color='tab:blue')\n",
    "#axins.errorbar(N_vals, qsim_avgs[:,0], yerr=qsim_avgs[:,1], fmt='.-', capsize=2, label='Qsim', color='tab:red')\n",
    "axins.errorbar(N_vals, spynoza_avgs[:,0], yerr=spynoza_avgs[:,1], fmt='.-', capsize=2, label='Spynoza', color='tab:red')\n",
    "\n",
    "axins.errorbar(N_vals, qulacs_avgs[:,0], yerr=qulacs_avgs[:,1], fmt='.-', capsize=2, label='Qulacs', color='tab:green')\n",
    "axins.hlines(0, N_vals[0], N_vals[-1],ls='--',color='k', lw = 1)\n",
    "\n",
    "axins.set_xticks([4,5,6,7,8,9,10,11,12])\n",
    "#axins.set_yticks([])\n",
    "# sub region of the original image\n",
    "x1, x2, y1, y2 = 3.99, 12.01, -0.005, 0.03\n",
    "axins.set_xlim(x1, x2)\n",
    "axins.set_ylim(y1, y2)\n",
    "axins.tick_params(axis='both', which='major', labelsize=8)\n",
    "ax.indicate_inset_zoom(axins, edgecolor=\"black\")\n",
    "\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "#plt.savefig('simulator_comparison_3.png', dpi=400)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac0b95da287bfdc4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
