{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-04T17:30:30.815556Z",
     "start_time": "2024-02-04T17:30:28.473511Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "\n",
    "from src.CPQAOA import CP_QAOA\n",
    "from src.QAOA import QAOA\n",
    "from src.Chain import Chain\n",
    "from src.Tools import (portfolio_metrics, \n",
    "                       min_cost_partition, \n",
    "                       get_qubo, \n",
    "                       normalized_cost, \n",
    "                       qubo_limits, \n",
    "                       check_qubo)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def simulate(datapoint):\n",
    "    # Defining topology\n",
    "    my_chain = Chain(N_qubits=datapoint['N'])\n",
    "    my_chain.set_initialization_strategy(strategy=datapoint['init_strat'])\n",
    "    \n",
    "    # Deciding between grid and 1d chain topology\n",
    "    my_topology = my_chain\n",
    "    \n",
    "    # Generating random problem instance \n",
    "    expected_returns, covariances = portfolio_metrics(n=datapoint['N'], seed=datapoint['seed'])\n",
    "    \n",
    "    # Retrieving C_min, C_max and corresponding states for original portfolio problem\n",
    "    constrained_result, full_result, lmbda = min_cost_partition(nr_qubits=datapoint['N'],\n",
    "                                                                k=datapoint['k'],\n",
    "                                                                mu=expected_returns,\n",
    "                                                                sigma=covariances,\n",
    "                                                                alpha=datapoint['alpha'])\n",
    "    \n",
    "    portfolio_subspace_max_cost, portfolio_subspace_min_cost, portfolio_subspace_min_state = constrained_result['c_max'], constrained_result['c_min'], constrained_result['s']\n",
    "    #full_space_max_cost = full_result['c_max']\n",
    "    portfolio_subspace_min_state_str = ''.join([str(_) for _ in portfolio_subspace_min_state])\n",
    "\n",
    "    # Generating QUBO corresponding to current problem instance\n",
    "    Q, offset = get_qubo(mu=expected_returns,\n",
    "                         sigma=covariances, \n",
    "                         alpha=datapoint['alpha'],\n",
    "                         lmbda=lmbda+1e-8, # Adding small constant purposely\n",
    "                         k=datapoint['k'])\n",
    "    QUBO_limits = qubo_limits(Q=Q,offset=offset)\n",
    "    qubo_min_cost, qubo_max_cost = QUBO_limits['c_min'], QUBO_limits['c_max']\n",
    "    qubo_min_state, qubo_max_state = QUBO_limits['min_state'], QUBO_limits['max_state']\n",
    "    check_qubo(QUBO_matrix=Q, QUBO_offset=offset, expected_returns=expected_returns, covariances=covariances, alpha=datapoint['alpha'], k=datapoint['k'])\n",
    "    qubo_min_state_str = ''.join([str(_) for _ in qubo_min_state])\n",
    "\n",
    "    \n",
    "    if not portfolio_subspace_min_state_str == qubo_min_state_str:\n",
    "        raise RuntimeError(f'portfolio_subspace_min_state_str: {portfolio_subspace_min_state_str}, qubo_min_state_str={qubo_min_state_str}'+f'Min. cost of qubo is: {qubo_min_cost}, but min. cost of constrained portfolio is: {portfolio_subspace_min_cost}.')\n",
    "    \n",
    "    if not np.isclose(qubo_min_cost,portfolio_subspace_min_cost):\n",
    "        raise RuntimeError(f'Min. cost of qubo is: {qubo_min_cost}, but min. cost of constrained portfolio is: {portfolio_subspace_min_cost}.')\n",
    "    \n",
    "    if not qubo_max_cost >= portfolio_subspace_max_cost:\n",
    "        raise RuntimeError(f'Max. cost of qubo: {qubo_max_cost}, max. cost of portfolio subspace: {portfolio_subspace_max_cost} (should be qubo max. >= constrained portfolio max)')\n",
    "\n",
    "    \n",
    "    # Generating instances of ansatz'\n",
    "    CP_z_phase_ansatz = CP_QAOA(N_qubits=datapoint['N'],\n",
    "                     cardinality=datapoint['k'],\n",
    "                     layers=datapoint['layers'],\n",
    "                     topology=my_topology,\n",
    "                     QUBO_matrix=Q,\n",
    "                     with_next_nearest_neighbors=datapoint['w_nnn'],\n",
    "                     with_gradient=True,\n",
    "                     approximate_hamiltonian=True,\n",
    "                     with_z_phase=datapoint['w_z_phase'])\n",
    "    \n",
    "    NORMAL_ansatz = QAOA(N_qubits=datapoint['N'],\n",
    "                     layers=datapoint['layers'],\n",
    "                     QUBO_matrix=Q,\n",
    "                     QUBO_offset=offset,\n",
    "                     constraining_mixer=False,\n",
    "                     Topology=my_topology)\n",
    "    \n",
    "    # Choosing optimizer for scipy\n",
    "    available_methods = ['COBYLA', 'Nelder-Mead', 'BFGS']\n",
    "    optimizer_method = available_methods[0]\n",
    "    \n",
    "    # Generating callback function for plotting\n",
    "    CP_z_phase_costs = [] # Normalized costs\n",
    "    CP_z_phase_probs = [] # probability of optimal state\n",
    "    def CP_z_phase_callback_function(x):\n",
    "        _dict_ = CP_z_phase_ansatz.get_state_probabilities(flip_states=False)\n",
    "        # N.B. Normalizing w. respect to full space max cost\n",
    "        _cost_ = normalized_cost(result=_dict_,\n",
    "                                 QUBO_matrix=Q,\n",
    "                                 QUBO_offset=offset,\n",
    "                                 max_cost=portfolio_subspace_max_cost, \n",
    "                                 min_cost=qubo_min_cost)\n",
    "        if portfolio_subspace_min_state_str in list(_dict_.keys()):\n",
    "            CP_z_phase_probs.append(_dict_[portfolio_subspace_min_state_str])\n",
    "        else:\n",
    "            CP_z_phase_probs.append(0)\n",
    "        CP_z_phase_costs.append(_cost_)\n",
    "        \n",
    "    # Generating callback function for plotting\n",
    "    NORMAL_costs = [] # Normalized costs\n",
    "    NORMAL_probs = [] # probability of optimal state\n",
    "    def NORMAL_callback_function(x):\n",
    "        _dict_ = NORMAL_ansatz.get_state_probabilities(flip_states=False)\n",
    "        # N.B. Normalizing w. respect to full space max cost\n",
    "        _cost_ = normalized_cost(result=_dict_,\n",
    "                                 QUBO_matrix=Q,\n",
    "                                 QUBO_offset=offset,\n",
    "                                 max_cost=portfolio_subspace_max_cost, \n",
    "                                 min_cost=qubo_min_cost)\n",
    "        if portfolio_subspace_min_state_str in list(_dict_.keys()):\n",
    "            NORMAL_probs.append(_dict_[portfolio_subspace_min_state_str])\n",
    "        else:\n",
    "            NORMAL_probs.append(0)\n",
    "        NORMAL_costs.append(_cost_)\n",
    "    \n",
    "    # Generating initial guess for rotation angles\n",
    "    np.random.seed(datapoint['seed'])\n",
    "    theta_min, theta_max = -2*np.pi, 2*np.pi\n",
    "    N_angles = datapoint['layers'] * len(my_topology.get_NN_indices())\n",
    "    if datapoint['w_nnn']:\n",
    "        N_angles = datapoint['layers'] * len(my_topology.get_NNN_indices())\n",
    "    if datapoint['w_z_phase']:\n",
    "        N_angles += datapoint['N'] * datapoint['layers']\n",
    "    CP_z_phase_theta_i = np.random.uniform(low=theta_min, high=theta_max, size=N_angles)\n",
    "    np.random.seed(datapoint['seed'])\n",
    "    N_angles = 2 * datapoint['layers']\n",
    "    NORMAL_theta_i = np.random.uniform(low=theta_min, high=theta_max, size=N_angles)\n",
    "    \n",
    "    CP_z_phase_res = sc.optimize.minimize(fun=CP_z_phase_ansatz.get_cost, \n",
    "                                      x0=CP_z_phase_theta_i,\n",
    "                                      method=optimizer_method,\n",
    "                                      options={'disp': False, \n",
    "                                               'maxiter': datapoint['max_iter']},\n",
    "                                      callback=CP_z_phase_callback_function)\n",
    "    \n",
    "    NORMAL_res = sc.optimize.minimize(fun=NORMAL_ansatz.get_cost, \n",
    "                                      x0=NORMAL_theta_i,\n",
    "                                      method=optimizer_method,\n",
    "                                      options={'disp': False, \n",
    "                                               'maxiter': datapoint['max_iter']},\n",
    "                                      callback=NORMAL_callback_function)\n",
    "\n",
    "    return {'N': datapoint['N'],\n",
    "            'k': datapoint['k'],\n",
    "            'alpha': datapoint['alpha'],\n",
    "            'max_iter': datapoint['max_iter'],\n",
    "            'topology': my_topology,\n",
    "            'seed': datapoint['seed'],\n",
    "            'next nearest neighbor': datapoint['w_nnn'],\n",
    "            'layers': datapoint['layers'],\n",
    "            'z-phase': datapoint['w_z_phase'],\n",
    "            'QAOA': (NORMAL_probs,NORMAL_costs,NORMAL_res),\n",
    "            'CP_VQA': (CP_z_phase_probs, CP_z_phase_costs, CP_z_phase_res)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T17:30:30.826537Z",
     "start_time": "2024-02-04T17:30:30.815116Z"
    }
   },
   "id": "1877d3e6c4a66e46",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# Number of Qubits \n",
    "N_vals = [3,4,5,6,7,8,9,10]\n",
    "# alpha in: s^T*mu + alpha*(s^T*Covar*s)\n",
    "alpha=0.5\n",
    "# Maximal number of iterations for classical solver\n",
    "max_iter=1500\n",
    "# Using next nearest neighbors (in 1D chain model)\n",
    "w_next_nearest_neighbors = True\n",
    "# Number of layer repetitions\n",
    "layer_dict = {3:1,\n",
    "              4:1,\n",
    "              5:2,\n",
    "              6:2,\n",
    "              7:2,\n",
    "              8:2,\n",
    "              9:2,\n",
    "              10:2}\n",
    "\n",
    "\n",
    "initialization_strategies = {3:np.array([0,1,0]),\n",
    "                             4:np.array([0,1,0,1]),\n",
    "                             5:np.array([0,1,0,1,0]),\n",
    "                             6:np.array([0,1,0,1,0,1]),\n",
    "                             7:np.array([0,1,0,1,0,1,0]),\n",
    "                             8:np.array([0,1,0,1,0,1,0,1]),\n",
    "                             9:np.array([0,1,0,1,0,1,0,1,0]),\n",
    "                             10:np.array([0,1,0,1,0,1,0,1,0,1]),}\n",
    "\n",
    "\n",
    "N_SEEDS = 7*50\n",
    "N_jobs = os.cpu_count()-1\n",
    "\n",
    "datapoints = []\n",
    "for N in N_vals:\n",
    "    for seed in range(N_SEEDS):\n",
    "        k = N // 2\n",
    "        N_layers = layer_dict[N]\n",
    "        dp = {'N': N, 'k': k, 'alpha': alpha, 'max_iter': max_iter, 'seed': seed+1000, 'w_nnn': w_next_nearest_neighbors, \n",
    "              'layers': N_layers, 'w_z_phase': False, 'init_strat': initialization_strategies[N]}\n",
    "        datapoints.append(dp)\n",
    "        \n",
    "r = Parallel(n_jobs=N_jobs, verbose=51, backend='loky')(delayed(simulate)(datapoint) for datapoint in datapoints)\n",
    "\n",
    "\n",
    "# Initialize the largest index number\n",
    "max_idx = -1\n",
    "\n",
    "for idx, result in enumerate(r):\n",
    "    # Generate the initial filename\n",
    "    filename = f'fig_10_results/res_{idx}.pkl'\n",
    "\n",
    "    # Check if this file already exists\n",
    "    if os.path.exists(filename):\n",
    "        # If the file exists, check if the index is larger than the maximum encountered so far\n",
    "        max_idx = max(max_idx, idx)\n",
    "        \n",
    "        # Find the next available index\n",
    "        new_idx = max_idx + 1\n",
    "        while os.path.exists(f'fig_10_results/res_{new_idx}.pkl'):\n",
    "            new_idx += 1\n",
    "        \n",
    "        # Update the filename and max_idx\n",
    "        filename = f'fig_10_results/res_{new_idx}.pkl'\n",
    "        max_idx = new_idx\n",
    "\n",
    "    # Write to the file\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(result, file)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-04T17:30:39.500781Z"
    }
   },
   "id": "206a2a895a66dc64"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results = []\n",
    "for filename in os.listdir('fig_10_results'):\n",
    "    if filename != '.DS_Store':\n",
    "        with open('fig_10_results/'+filename, 'rb') as file:\n",
    "            results.append(pickle.load(file))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T14:47:19.999070Z",
     "start_time": "2024-02-04T14:47:18.695441Z"
    }
   },
   "id": "66a03026340607ff",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1000]['N']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T14:50:45.881315Z",
     "start_time": "2024-02-04T14:50:45.874394Z"
    }
   },
   "id": "1477f082b8446677"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [15], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m CP_VQA_probs, CP_VQA_costs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mN=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mN\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m:[] \u001B[38;5;28;01mfor\u001B[39;00m N \u001B[38;5;129;01min\u001B[39;00m N_vals}, {\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mN=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mN\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m:[] \u001B[38;5;28;01mfor\u001B[39;00m N \u001B[38;5;129;01min\u001B[39;00m N_vals}\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m results:\n\u001B[0;32m----> 5\u001B[0m     _N_ \u001B[38;5;241m=\u001B[39m \u001B[43mresults\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mN\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28mprint\u001B[39m(_N_)\n\u001B[1;32m      7\u001B[0m     p_qaoa, c_qaoa, res_qaoa \u001B[38;5;241m=\u001B[39m results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mQAOA\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[0;31mTypeError\u001B[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "N_vals = [3,4,5,6,7,8,9,10]\n",
    "QAOA_probs, QAOA_costs = {f'N={N}':[] for N in N_vals}, {f'N={N}':[] for N in N_vals}\n",
    "CP_VQA_probs, CP_VQA_costs = {f'N={N}':[] for N in N_vals}, {f'N={N}':[] for N in N_vals}\n",
    "for result in results:\n",
    "    _N_ = result['N']\n",
    "    p_qaoa, c_qaoa, res_qaoa = result['QAOA']\n",
    "    QAOA_probs[f'N={_N_}'].append(np.max(p_qaoa))\n",
    "    QAOA_costs[f'N={_N_}'].append(np.min(c_qaoa))\n",
    "    \n",
    "    p_cp_vqa, c_cp_vqa, res_cp_vqa = result['CP_VQA']\n",
    "    CP_VQA_probs[f'N={_N_}'].append(np.max(p_cp_vqa))\n",
    "    CP_VQA_costs[f'N={_N_}'].append(np.min(c_cp_vqa))\n",
    "\n",
    "for N in N_vals:\n",
    "    mu, std = np.mean(QAOA_probs[f'N={N}']), np.std(QAOA_probs[f'N={N}'])\n",
    "    QAOA_probs[f'N={N}'] = mu, std\n",
    "    \n",
    "    mu, std = np.mean(QAOA_costs[f'N={N}']), np.std(QAOA_costs[f'N={N}'])\n",
    "    QAOA_costs[f'N={N}'] = mu, std\n",
    "    \n",
    "    mu, std = np.mean(CP_VQA_probs[f'N={N}']), np.std(CP_VQA_probs[f'N={N}'])\n",
    "    CP_VQA_probs[f'N={N}'] = mu, std\n",
    "    \n",
    "    mu, std = np.mean(CP_VQA_costs[f'N={N}']), np.std(CP_VQA_costs[f'N={N}'])\n",
    "    CP_VQA_costs[f'N={N}'] = mu, std"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T14:50:15.388105Z",
     "start_time": "2024-02-04T14:50:15.371673Z"
    }
   },
   "id": "5e0ae48c330b88c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7401ff134060b8fc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
